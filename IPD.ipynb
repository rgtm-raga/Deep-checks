{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3eae3a-9f4e-4cfb-afb0-480052b6f819",
   "metadata": {},
   "source": [
    "## Image property drift without deepcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a0aeccb-f248-49b2-9569-54b5bdb5a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gudhi\n",
    "# !pip install POT\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da32aeee-39fa-421b-ab51-15d62c04f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL.ImageStat import Stat\n",
    "from gudhi.wasserstein import wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69591872-78a2-47af-b0ed-e49b6df4883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"dataset/virat_1\"\n",
    "test_dir=\"dataset/ADAS\"\n",
    "\n",
    "def area(image):\n",
    "    image=np.array(image)\n",
    "    height,width,_=image.shape\n",
    "    return height*width\n",
    "    \n",
    "def aspect_ratio(image):\n",
    "    image=np.array(image)\n",
    "    height,width,_=image.shape\n",
    "    return height/width\n",
    "\n",
    "def brightness(image):\n",
    "    image=np.uint8(image*255)\n",
    "    image=Image.fromarray(image)\n",
    "    image=image.convert('L')\n",
    "    return Stat(image).mean[0]\n",
    "\n",
    "def mbr_intesity(image,eps=0.0000001):\n",
    "    # image=np.array(image)/255\n",
    "    height,width,_=image.shape\n",
    "    # imb=np.zeros(image.shape) #\n",
    "    # for i in range(height):\n",
    "    #     for j in range(width):\n",
    "    #         imb[i,j]=image[i,j,2]/(sum(image[i,j,:])+eps) # red\n",
    "    # return np.sum(imb)/(height*width) #\n",
    "    return np.sum(image[:,:,2]/(np.sum(image,axis=2)+eps))/(height*width)\n",
    "    \n",
    "def mgr_intesity(image,eps=0.0000001):\n",
    "    # image=np.array(image)/255\n",
    "    height,width,_=image.shape\n",
    "    # img=np.zeros(image.shape) #\n",
    "    # for i in range(height):\n",
    "    #     for j in range(width):\n",
    "    #         img[i,j]=image[i,j,1]/(sum(image[i,j,:])+eps) # red\n",
    "    # return np.sum(img)/(height*width)\n",
    "    return np.sum(image[:,:,1]/(np.sum(image,axis=2)+eps))/(height*width)\n",
    "    \n",
    "\n",
    "def mrr_intesity(image,eps=0.0000001):\n",
    "    # image=np.array(image)/255\n",
    "    height,width,_=image.shape\n",
    "    # imr=np.zeros(image.shape) #\n",
    "    # for i in range(height):\n",
    "    #     for j in range(width):\n",
    "    #         imr[i,j]=image[i,j,0]/(sum(image[i,j,:])+eps) # red\n",
    "    # return np.sum(imr)/(height*width)\n",
    "    return np.sum(image[:,:,0]/(np.sum(image,axis=2)+eps))/(height*width)\n",
    "    \n",
    "\n",
    "def rms_contrast(image):\n",
    "    image=np.uint8(image*255)\n",
    "    img_grey=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    return img_grey.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5d6c981-2669-46a0-8b9b-51934baa91b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area': 0.03290915489196777,\n",
       " 'aspect_ratio': 0.004182577133178711,\n",
       " 'brightness': 0.010503292083740234,\n",
       " 'mbr_intesity': 0.023222684860229492,\n",
       " 'mgr_intesity': 0.02225041389465332,\n",
       " 'mrr_intesity': 0.022437572479248047,\n",
       " 'rms_contrast': 0.012737274169921875}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties=['Area', 'Aspect Ratio', 'Brightness', 'Mean Blue Relative Intensity', 'Mean Green Relative Intensity', 'Mean Red Relative Intensity', 'RMS Contrast']\n",
    "image_properties=[]\n",
    "time_taken={}\n",
    "t1=time()\n",
    "for img in os.listdir(train_dir)[:1]:\n",
    "    image_property=[]\n",
    "    img_path=os.path.join(train_dir,img)\n",
    "    # image=Image.open(img_path)\n",
    "    image=cv2.imread(img_path)/255\n",
    "    image_property.append(area(image))\n",
    "    t2=time()\n",
    "    time_taken[\"area\"]=t2-t1\n",
    "    image_property.append(aspect_ratio(image))\n",
    "    t3=time()\n",
    "    time_taken[\"aspect_ratio\"]=t3-t2\n",
    "    image_property.append(brightness(image))\n",
    "    t4=time()\n",
    "    time_taken[\"brightness\"]=t4-t3\n",
    "    image_property.append(mbr_intesity(image))\n",
    "    t5=time()\n",
    "    time_taken[\"mbr_intesity\"]=t5-t4\n",
    "    image_property.append(mgr_intesity(image))\n",
    "    t6=time()\n",
    "    time_taken[\"mgr_intesity\"]=t6-t5\n",
    "    image_property.append(mrr_intesity(image))\n",
    "    t7=time()\n",
    "    time_taken[\"mrr_intesity\"]=t7-t6\n",
    "    image_property.append(rms_contrast(image))\n",
    "    t8=time()\n",
    "    time_taken[\"rms_contrast\"]=t8-t7\n",
    "    image_properties.append(image_property)\n",
    "train_features=np.array(image_properties)\n",
    "# train_features=pd.DataFrame(train_features,columns=properties)\n",
    "time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "057102a3-7486-4b4a-ab92-9f0ef07d71b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Aspect Ratio</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Mean Blue Relative Intensity</th>\n",
       "      <th>Mean Green Relative Intensity</th>\n",
       "      <th>Mean Red Relative Intensity</th>\n",
       "      <th>RMS Contrast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921600.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>117.240958</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>0.332825</td>\n",
       "      <td>0.354305</td>\n",
       "      <td>72.378711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area  Aspect Ratio  Brightness  Mean Blue Relative Intensity  \\\n",
       "0  921600.0        0.5625  117.240958                       0.31287   \n",
       "\n",
       "   Mean Green Relative Intensity  Mean Red Relative Intensity  RMS Contrast  \n",
       "0                       0.332825                     0.354305     72.378711  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features=pd.DataFrame(train_features,columns=properties)\n",
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c35b29-1795-4a05-ae73-5ceeba071779",
   "metadata": {},
   "source": [
    "{'area': 0.03642582893371582,\n",
    " 'aspect_ratio': 0.003378629684448242,\n",
    " 'brightness': 0.009185075759887695,\n",
    " 'mbr_intesity': 3.8872950077056885,\n",
    " 'mgr_intesity': 3.908198595046997,\n",
    " 'mrr_intesity': 3.9440712928771973,\n",
    " 'rms_contrast': 0.01011204719543457}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9720fdb8-914a-4e59-b2fc-d513ebb5d95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.191571950912476"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties=['Area', 'Aspect Ratio', 'Brightness', 'Mean Blue Relative Intensity', 'Mean Green Relative Intensity', 'Mean Red Relative Intensity', 'RMS Contrast']\n",
    "image_properties=[]\n",
    "t1=time()\n",
    "for img in os.listdir(train_dir)[:101]:\n",
    "    image_property=[]\n",
    "    img_path=os.path.join(train_dir,img)\n",
    "    # image=Image.open(img_path)\n",
    "    image=cv2.imread(img_path)/255\n",
    "    image_property.append(area(image))\n",
    "    image_property.append(aspect_ratio(image))\n",
    "    image_property.append(brightness(image))\n",
    "    image_property.append(mbr_intesity(image))\n",
    "    image_property.append(mgr_intesity(image))\n",
    "    image_property.append(mrr_intesity(image))\n",
    "    image_property.append(rms_contrast(image))\n",
    "    image_properties.append(image_property)\n",
    "train_features=np.array(image_properties)\n",
    "train_features=pd.DataFrame(train_features,columns=properties)\n",
    "\n",
    "image_properties=[]\n",
    "for img in os.listdir(test_dir):\n",
    "    if img != '.ipynb_checkpoints':\n",
    "        image_property=[]\n",
    "        img_path=os.path.join(test_dir,img)\n",
    "        # image=Image.open(img_path)\n",
    "        image=cv2.imread(img_path)/255\n",
    "        image_property.append(area(image))\n",
    "        image_property.append(aspect_ratio(image))\n",
    "        image_property.append(brightness(image))\n",
    "        image_property.append(mbr_intesity(image))\n",
    "        image_property.append(mgr_intesity(image))\n",
    "        image_property.append(mrr_intesity(image))\n",
    "        image_property.append(rms_contrast(image))\n",
    "        image_properties.append(image_property)\n",
    "test_features=np.array(image_properties)\n",
    "test_features=pd.DataFrame(test_features,columns=properties)\n",
    "time_taken=time()-t1\n",
    "time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a05300e-3be7-4ce9-83df-738c96616e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Area': -58170950.0,\n",
       " 'Aspect Ratio': -0.5625,\n",
       " 'Brightness': -3936.938375108506,\n",
       " 'Mean Blue Relative Intensity': 40.25033453310319,\n",
       " 'Mean Green Relative Intensity': 29.615994457610054,\n",
       " 'Mean Red Relative Intensity': 19.04523517348781,\n",
       " 'RMS Contrast': -2008.6969795533714}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.remove(os.path.join(test_dir,img))\n",
    "drift_score={}\n",
    "for prop in properties:\n",
    "    drift_score[prop]=wasserstein_distance(np.array(train_features[[prop,\"index\"]]),np.array(test_features[[prop,\"index\"]]))\n",
    "    \n",
    "drift_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aeb0dc3-f94b-4905-80e9-257440dcc86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Area': 0.0,\n",
       " 'Aspect Ratio': 0.999999298398835,\n",
       " 'Brightness': 0.9999316293449274,\n",
       " 'Mean Blue Relative Intensity': 1.0,\n",
       " 'Mean Green Relative Intensity': 0.9999998171882578,\n",
       " 'Mean Red Relative Intensity': 0.9999996354695138,\n",
       " 'RMS Contrast': 0.9999647771628906}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drifts=[]\n",
    "for key in drift_score.keys():\n",
    "    drifts.append(drift_score[key])\n",
    "mx,mn=max(drifts),min(drifts)\n",
    "new_drifts={}\n",
    "for key in drift_score.keys():\n",
    "    new_drifts[key]=(drift_score[key]-mn)/(mx-mn)\n",
    "new_drifts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a17fb-44f7-4f78-968e-a172365efe13",
   "metadata": {},
   "source": [
    "## Image property drift with deepcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4edd20b3-1d32-4a36-902b-cda8e118991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,argparse\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import deepchecks\n",
    "from deepchecks.vision import VisionData\n",
    "from deepchecks.vision.checks import ImagePropertyDrift\n",
    "\n",
    "from typing import Any, Dict, Mapping, Optional, Sequence, Union\n",
    "\n",
    "import torch\n",
    "from ignite.metrics import Metric\n",
    "from torch import nn\n",
    "\n",
    "from deepchecks.core.check_result import CheckResult\n",
    "from deepchecks.core.checks import DatasetKind, ModelOnlyBaseCheck, SingleDatasetBaseCheck, TrainTestBaseCheck\n",
    "from deepchecks.utils.ipython import ProgressBarGroup\n",
    "from deepchecks.vision import deprecation_warnings  # pylint: disable=unused-import # noqa: F401\n",
    "from deepchecks.vision._shared_docs import docstrings\n",
    "from deepchecks.vision.batch_wrapper import Batch\n",
    "from deepchecks.vision.context import Context\n",
    "from deepchecks.vision.utils.vision_properties import STATIC_PROPERTIES_FORMAT\n",
    "from deepchecks.vision.vision_data import VisionData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bbd614f-9e3b-4ff4-beb6-35b0d44dbf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = train_dir\n",
    "test_data_dir = test_dir\n",
    "recursive=True\n",
    "class DatasetLoader(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        img_paths = []\n",
    "        img_labels = []\n",
    "        label = root.split('/')[-1]       \n",
    "        if recursive :\n",
    "            for filename in os.listdir(root):\n",
    "                if filename.split('.')[1] not in ['png','jpg','jpeg'] : \n",
    "                    continue\n",
    "                img_paths.append(os.path.join(root,filename))\n",
    "                img_labels.append(label)\n",
    "            img_paths=img_paths[:101]\n",
    "        else :\n",
    "            categories = os.listdir(root)\n",
    "            for cat_index, cat in enumerate(categories):\n",
    "                directory = os.path.join(root,cat)\n",
    "                for filename in os.listdir(directory):\n",
    "                    if filename.split('.')[1] not in ['png','jpg','jpeg'] : \n",
    "                        continue\n",
    "                    img_paths.append(os.path.join(directory,filename))\n",
    "                    img_labels.append(cat_index)\n",
    "\n",
    "\n",
    "        self.images_filepaths = img_paths\n",
    "        self.labels = img_labels\n",
    "\n",
    "    def image_from_path(self,path) :\n",
    "        trans = transforms.ToTensor()\n",
    "        return trans(Image.open(path))\n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_from_path(self.images_filepaths[idx]), self.labels[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "class DeepCheckData(VisionData):\n",
    "    def batch_to_images(self, batch):\n",
    "        imgs = batch[0].detach().numpy().transpose((0, 2, 3, 1))\n",
    "        return imgs*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e893a82-8035-4904-96af-a087d7a0ee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - batch_to_labels() was not implemented, some checks will not run\n",
      "deepchecks - WARNING - batch_to_labels() was not implemented, some checks will not run\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - Checks will run on the cpu by default. To make use of cuda devices, use the device parameter in the run function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Aspect Ratio': 0,\n",
       " 'Area': 1.0,\n",
       " 'Brightness': 0.9701847949224576,\n",
       " 'RMS Contrast': 0.7912360467984437,\n",
       " 'Mean Red Relative Intensity': 0.8091872211723896,\n",
       " 'Mean Green Relative Intensity': 0.8833973986096024,\n",
       " 'Mean Blue Relative Intensity': 0.5636379491147916}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = DatasetLoader(train_data_dir)\n",
    "val_dataset = DatasetLoader(test_data_dir)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True,generator=torch.Generator())\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True,generator=torch.Generator())\n",
    "\n",
    "train_ds = DeepCheckData(train_dataloader)\n",
    "test_ds = DeepCheckData(test_dataloader)\n",
    "\n",
    "check = ImagePropertyDrift()#.add_condition_drift_score_less_than(0.1)\n",
    "result = check.run(train_ds, test_ds)\n",
    "result.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665ed081-8da9-4b18-8a41-a8bf93ec95ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'properties' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m drift_score\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m      3\u001b[0m margin_quantile_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.025\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m \u001b[43mproperties\u001b[49m:\n\u001b[1;32m      5\u001b[0m     dist1,dist2\u001b[38;5;241m=\u001b[39mtrain_features[prop],test_features[prop]\n\u001b[1;32m      6\u001b[0m     dist1_qt_min, dist1_qt_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mquantile(dist1, [margin_quantile_filter, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m margin_quantile_filter])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'properties' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "drift_score={}\n",
    "margin_quantile_filter=0.025\n",
    "for prop in properties:\n",
    "    dist1,dist2=train_features[prop],test_features[prop]\n",
    "    dist1_qt_min, dist1_qt_max = np.quantile(dist1, [margin_quantile_filter, 1 - margin_quantile_filter])\n",
    "    dist2_qt_min, dist2_qt_max = np.quantile(dist2, [margin_quantile_filter, 1 - margin_quantile_filter])\n",
    "    dist1 = dist1[(dist1_qt_max >= dist1) & (dist1 >= dist1_qt_min)]\n",
    "    dist2 = dist2[(dist2_qt_max >= dist2) & (dist2 >= dist2_qt_min)]\n",
    "\n",
    "    val_max = np.max([np.max(dist1), np.max(dist2)])\n",
    "    val_min = np.min([np.min(dist1), np.min(dist2)])\n",
    "    if val_max == val_min:\n",
    "        drift_score[prop]=0\n",
    "    else:\n",
    "        dist1 = (dist1 - val_min) / (val_max - val_min)\n",
    "        dist2 = (dist2 - val_min) / (val_max - val_min)\n",
    "        drift_score[prop]=wasserstein_distance(dist1,dist2)\n",
    "drift_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ce171-d219-4475-9c9a-3b8396e5d062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
